[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Qinyi(Chloe) Hu",
    "section": "",
    "text": "Welcome to my website!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "My Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Let’s investigate the relationship between fuel efficiency (mpg) and engine displacement (disp) from the mtcars dataset. Those variables have a correlation of -0.85.\n\n\nHere is a plot:\n\nlibrary(tidyverse)\ndata(mtcars)\nmtcars |&gt;\n  ggplot(aes(mpg, disp)) + \n  geom_point(color=\"dodgerblue4\", size=2)"
  },
  {
    "objectID": "projects/project1/index.html#sub-header",
    "href": "projects/project1/index.html#sub-header",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Here is a plot:\n\nlibrary(tidyverse)\ndata(mtcars)\nmtcars |&gt;\n  ggplot(aes(mpg, disp)) + \n  geom_point(color=\"dodgerblue4\", size=2)"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "Analysis of Cars\n\n\n\n\n\n\nChloe Hu\n\n\nApr 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nQinyi Hu\n\n\nApr 19, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/project1/index.html",
    "href": "blog/project1/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Charitable giving constitutes a significant component of private contributions to public goods, with Americans donating consistently around 2% of GDP annually. Despite the scale and importance of these donations, fundraisers have historically relied on intuition and anecdotal evidence rather than rigorous experimental data to guide their strategies.\nDean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe standard letter asked for a donation in the usual way, without any mention of matching. This formed the control group. In contrast, both the matching grant letter and the challenge grant letter indicated that a fellow donor had agreed to match each contribution at a given rate, conditional on others also donating. While the language varied slightly between “matching” and “challenge” framing, both effectively served as treatment groups and were analyzed together in the main analysis.\nThe core question explored in this study was whether offering a match — and varying the generosity of that match — would affect donor behavior. The researchers were interested in how matching offers influence the extensive margin (whether people donate at all) and the intensive margin (how much they give).\nTo explore this, recipients were randomly assigned to fundraising letters that varied along three dimensions:\n\nMatch ratio: $1:$1, $2:$1, or $3:$1\nMaximum match amount: either $25,000, $50,000, $100,000, or left unspecified\nSuggested donation amount: tailored to each donor’s past behavior (equal to their highest previous gift, 1.25× that amount, or 1.5×)\n\nThe main outcome variables were whether a recipient donated and, if so, how much they contributed. Karlan and List found that simply including a matching offer — regardless of the exact match ratio — increased both the probability of giving and the revenue raised per letter. However, increasing the match ratio from $1:$1 to $2:$1 or $3:$1 yielded no additional benefit, suggesting diminishing or flat marginal returns from more generous matching. Additionally, the effect was stronger in red states (those that voted for George W. Bush in 2004), pointing to interesting heterogeneity in treatment effects across political environments.\nThis project seeks to replicate their results. Using the original dataset, we examine how the availability and generosity of matching gifts influence giving behavior. Along the way, we visualize treatment effects and estimate regression models similar to those in the published paper. The goal is not only to test the robustness of their results but also to understand what types of interventions are most effective in motivating donors."
  },
  {
    "objectID": "blog/project1/index.html#introduction",
    "href": "blog/project1/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Charitable giving constitutes a significant component of private contributions to public goods, with Americans donating consistently around 2% of GDP annually. Despite the scale and importance of these donations, fundraisers have historically relied on intuition and anecdotal evidence rather than rigorous experimental data to guide their strategies.\nDean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe standard letter asked for a donation in the usual way, without any mention of matching. This formed the control group. In contrast, both the matching grant letter and the challenge grant letter indicated that a fellow donor had agreed to match each contribution at a given rate, conditional on others also donating. While the language varied slightly between “matching” and “challenge” framing, both effectively served as treatment groups and were analyzed together in the main analysis.\nThe core question explored in this study was whether offering a match — and varying the generosity of that match — would affect donor behavior. The researchers were interested in how matching offers influence the extensive margin (whether people donate at all) and the intensive margin (how much they give).\nTo explore this, recipients were randomly assigned to fundraising letters that varied along three dimensions:\n\nMatch ratio: $1:$1, $2:$1, or $3:$1\nMaximum match amount: either $25,000, $50,000, $100,000, or left unspecified\nSuggested donation amount: tailored to each donor’s past behavior (equal to their highest previous gift, 1.25× that amount, or 1.5×)\n\nThe main outcome variables were whether a recipient donated and, if so, how much they contributed. Karlan and List found that simply including a matching offer — regardless of the exact match ratio — increased both the probability of giving and the revenue raised per letter. However, increasing the match ratio from $1:$1 to $2:$1 or $3:$1 yielded no additional benefit, suggesting diminishing or flat marginal returns from more generous matching. Additionally, the effect was stronger in red states (those that voted for George W. Bush in 2004), pointing to interesting heterogeneity in treatment effects across political environments.\nThis project seeks to replicate their results. Using the original dataset, we examine how the availability and generosity of matching gifts influence giving behavior. Along the way, we visualize treatment effects and estimate regression models similar to those in the published paper. The goal is not only to test the robustness of their results but also to understand what types of interventions are most effective in motivating donors."
  },
  {
    "objectID": "blog/project1/index.html#data",
    "href": "blog/project1/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nThe dataset used in this project comes from the original field experiment conducted by Karlan and List (2007). It contains information on 50,083 prior donors who were randomly assigned to receive one of several versions of a fundraising letter. Each row in the dataset represents a single individual, and the columns record treatment assignments, past donation behavior, observed giving outcomes, and various demographic and geographic characteristics.\n\nimport pandas as pd\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\nThe data includes several important variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\nBelow, we summarize the dataset:\n\ndf[['gave', 'amount', 'hpa', 'freq', 'years']].describe()\n\n\n\n\n\n\n\n\ngave\namount\nhpa\nfreq\nyears\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50082.000000\n\n\nmean\n0.020646\n0.915694\n59.384975\n8.039355\n6.097540\n\n\nstd\n0.142197\n8.707393\n71.179871\n11.394454\n5.503492\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n30.000000\n2.000000\n2.000000\n\n\n50%\n0.000000\n0.000000\n45.000000\n4.000000\n5.000000\n\n\n75%\n0.000000\n0.000000\n60.000000\n10.000000\n9.000000\n\n\nmax\n1.000000\n400.000000\n1000.000000\n218.000000\n95.000000\n\n\n\n\n\n\n\n\ndf['treatment'].value_counts()\n\n1    33396\n0    16687\nName: treatment, dtype: int64\n\n\n\ndf[['treatment', 'gave', 'amount', 'hpa']].isnull().sum()\n\ntreatment    0\ngave         0\namount       0\nhpa          0\ndtype: int64\n\n\nWe observe that treatment and control groups are appropriately split, with no major issues related to missing values in the core outcome variables. This ensures a clean setup for replicating the main analysis from the original paper.\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I compare baseline characteristics between the treatment and control groups. If the randomization was successful, there should be no statistically significant differences in these pre-treatment covariates. To test this, I examine selected variables using both two-sample t-tests and linear regressions, and confirm that both methods yield equivalent results.\nBelow, I analyze the variable mrm2 — the number of months since the individual’s last donation — as a representative pre-treatment covariate. I also test additional variables such as hpa (highest previous contribution) and years (years since first donation). These variables are all unrelated to the treatment assignment and therefore should be balanced across groups.\n1. Balance Test for mrm2 (Months Since Last Donation)\nWe first compute the t-statistic manually:\n\n# Select values and drop missing observations\ntreat = df[df['treatment'] == 1]['mrm2'].dropna()\ncontrol = df[df['control'] == 1]['mrm2'].dropna()\n\n# Means, variances, sample sizes\nx1_bar, x0_bar = treat.mean(), control.mean()\ns1_sq, s0_sq = treat.var(ddof=1), control.var(ddof=1)\nn1, n0 = treat.shape[0], control.shape[0]\n\n# Manual t-statistic\nt_stat = (x1_bar - x0_bar) / ((s1_sq / n1 + s0_sq / n0) ** 0.5)\nt_stat\n\n0.11953155228176904\n\n\nNow we use a regression to estimate the same difference:\n\n# Regression of months since last donation on treatment\n# Intercept = control group mean; treatment coefficient = difference\nimport statsmodels.formula.api as smf\n\nmodel_mrm2 = smf.ols('mrm2 ~ treatment', data=df).fit()\nmodel_mrm2.summary2().tables[1]\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\n\n\nIntercept\n12.998142\n0.093526\n138.978873\n0.000000\n12.814830\n13.181454\n\n\ntreatment\n0.013686\n0.114534\n0.119492\n0.904886\n-0.210801\n0.238173\n\n\n\n\n\n\n\n2. Balance Test for hpa (Highest Previous Contribution)\n\ntreat = df[df['treatment'] == 1]['hpa'].dropna()\ncontrol = df[df['control'] == 1]['hpa'].dropna()\n\nx1_bar, x0_bar = treat.mean(), control.mean()\ns1_sq, s0_sq = treat.var(ddof=1), control.var(ddof=1)\nn1, n0 = treat.shape[0], control.shape[0]\n\nt_stat = (x1_bar - x0_bar) / ((s1_sq / n1 + s0_sq / n0) ** 0.5)\nt_stat\n\n0.9703896722043864\n\n\n\nmodel_hpa = smf.ols('hpa ~ treatment', data=df).fit()\nmodel_hpa.summary2().tables[1]\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\n\n\nIntercept\n58.960167\n0.551002\n107.005425\n0.000000\n57.880198\n60.040137\n\n\ntreatment\n0.637075\n0.674762\n0.944148\n0.345099\n-0.685467\n1.959617\n\n\n\n\n\n\n\n3. Balance Test for years (Years Since Initial Donation)\n\ntreat = df[df['treatment'] == 1]['years'].dropna()\ncontrol = df[df['control'] == 1]['years'].dropna()\n\nx1_bar, x0_bar = treat.mean(), control.mean()\ns1_sq, s0_sq = treat.var(ddof=1), control.var(ddof=1)\nn1, n0 = treat.shape[0], control.shape[0]\n\nt_stat = (x1_bar - x0_bar) / ((s1_sq / n1 + s0_sq / n0) ** 0.5)\nt_stat\n\n-1.0909175279573782\n\n\n\nmodel_years = smf.ols('years ~ treatment', data=df).fit()\nmodel_years.summary2().tables[1]\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\n\n\nIntercept\n6.135914\n0.042604\n144.022723\n0.000000\n6.052410\n6.219418\n\n\ntreatment\n-0.057549\n0.052173\n-1.103038\n0.270016\n-0.159809\n0.044711\n\n\n\n\n\n\n\nFor all three variables, both testing methods yielded consistent results: there were no statistically significant differences between the groups. The estimated differences were small, the t-statistics did not exceed standard critical values, and p-values were well above the conventional 0.05 level. The regression coefficients on the treatment variable mirrored the difference-in-means estimates, confirming the equivalence of the two methods.\nThese findings are consistent with Table 1 from Karlan and List (2007), which shows that the means of these same variables are nearly identical across treatment and control groups. For example:\n\nmrm2: 13.012 (treatment) vs. 12.998 (control)\nhpa: 59.60 (treatment) vs. 58.96 (control)\nyears: 6.08 (treatment) vs. 6.14 (control)\n\nNone of these differences are large enough to raise concerns about imbalance.\nTable 1 serves a critical purpose in field experiment papers: it reassures the reader that the random assignment was implemented correctly. In a randomized controlled trial (RCT), we expect pre-treatment characteristics to be balanced across groups. If large imbalances were found, this might indicate flaws in the randomization or possible selection bias. Since Table 1 shows no such imbalances, it supports the internal validity of the authors’ causal estimates."
  },
  {
    "objectID": "blog/project1/index.html#experimental-results",
    "href": "blog/project1/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation. The chart below shows the proportion of individuals who gave a donation in each group.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Calculate donation rate (mean of 'gave') for treatment and control\ngroup_means = df.groupby(\"treatment\")[\"gave\"].mean().reset_index()\ngroup_means[\"Group\"] = group_means[\"treatment\"].replace({1: \"Treatment\", 0: \"Control\"})\n\n# Create bar plot\nplt.figure(figsize=(6, 4))\nbars = plt.bar(group_means[\"Group\"], group_means[\"gave\"], color=[\"#1f77b4\", \"#ff7f0e\"])\nplt.ylabel(\"Proportion Who Donated\")\nplt.ylim(0, 0.03)\nplt.title(\"Donation Rate by Treatment Group\")\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2, height + 0.001, f\"{height:.3%}\", \n             ha='center', va='bottom', fontsize=10)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nDonation rates in treatment and control groups\n\n\n\n\nWe observe a clear difference in the donation rates: the treatment group had a higher proportion of donors than the control group. This aligns with the findings of Karlan and List (2007), who report that simply mentioning a matching grant significantly increases the probability of giving.\nIn our plot, the donation rate for the control group is approximately 1.8% while that for the treatment group is around 2.2%. This simple descriptive comparison already suggests a positive impact of matching on charitable behavior, which we will further test using other methods.\nWe now test whether receiving a matching donation offer increases the likelihood of making any donation. Specifically, we compare the response rate (gave == 1) between the treatment and control groups using t-test and linear regression.\n\ntreat = df[df['treatment'] == 1]['gave'].dropna()\ncontrol = df[df['control'] == 1]['gave'].dropna()\n\nx1_bar, x0_bar = treat.mean(), control.mean()\ns1_sq, s0_sq = treat.var(ddof=1), control.var(ddof=1)\nn1, n0 = treat.shape[0], control.shape[0]\n\nt_stat = (x1_bar - x0_bar) / ((s1_sq / n1 + s0_sq / n0) ** 0.5)\nt_stat\n\n3.2094621908279835\n\n\n\nmodel = smf.ols('gave ~ treatment', data=df).fit()\nmodel.summary2().tables[1]\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\n\n\nIntercept\n0.017858\n0.001101\n16.224643\n4.779032e-59\n0.015701\n0.020016\n\n\ntreatment\n0.004180\n0.001348\n3.101361\n1.927403e-03\n0.001538\n0.006822\n\n\n\n\n\n\n\nThe results show that people who received a treatment letter (i.e., a letter offering a matching donation) were significantly more likely to make a donation compared to those in the control group. The t-test and the regression both confirm that this difference is statistically significant.\nIn the regression, the intercept represents the control group’s donation rate (around 1.8%), and the coefficient on treatment shows the additional increase for the treatment group (roughly +0.4 percentage points). This matches the results in Table 2A, Panel A of the original paper (1.8% vs 2.2%).\nSo what does this result tell us about human behavior?\nSimply mentioning a match — even without changing the suggested amount — makes people more likely to give. This shows that social framing and perceived impact play a strong role in motivating charitable actions. People are more willing to give when they believe their donation is being “amplified” by a matching donor.\nThis insight is valuable for fundraisers: offering a match — even at a 1:1 ratio — is a low-cost but effective behavioral nudge to increase participation.\nWe now estimate a Probit model where the dependent variable is whether an individual donated (gave) and the independent variable is whether they received a matching grant offer (treatment).\n\nprobit_model = smf.probit(\"gave ~ treatment\", data=df).fit()\nprobit_model.summary2().tables[1]\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\n\n\nIntercept\n-2.100141\n0.023316\n-90.07277\n0.000000\n-2.145840\n-2.054443\n\n\ntreatment\n0.086785\n0.027879\n3.11293\n0.001852\n0.032143\n0.141426\n\n\n\n\n\n\n\nThe Probit regression shows that being assigned to the treatment group has a positive and statistically significant effect on the likelihood of donating. The estimated coefficient is 0.087, with a p-value &lt; 0.01, indicating strong evidence against the null hypothesis.\nThen we calculate the marginal effects:\n\nmfx = probit_model.get_margeff()\nmfx.summary()\n\n\nProbit Marginal Effects\n\n\nDep. Variable:\ngave\n\n\nMethod:\ndydx\n\n\nAt:\noverall\n\n\n\n\n\n\n\n\n\ndy/dx\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\ntreatment\n0.0043\n0.001\n3.104\n0.002\n0.002\n0.007\n\n\n\n\n\nWhen we compute the marginal effect, which represents the actual increase in donation probability, we obtain a value around 0.004, which exactly matches the reported result in Table 3, Column (1) of the paper. This means that being offered a matching gift increased the chance of donating by about 0.4 percentage points.\nAlthough this effect might sound small, it is statistically meaningful given the large sample size and low baseline donation rate (~1.8%). This reinforces the behavioral insight that even small framing changes, such as introducing a match, can have a measurable influence on charitable behavior.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different match ratios on the probability of donating. Specifically, I compare the response rate across $1:$1, $2:$1, and $3:$1 match treatments using two-sample t-tests.\n\nfrom scipy import stats\n\n# Filter only treatment group\ndf_treat = df[df['treatment'] == 1]\n\n# Split by match ratio\ngave_1to1 = df_treat[df_treat['ratio'] == 1]['gave'].dropna()\ngave_2to1 = df_treat[df_treat['ratio'] == 2]['gave'].dropna()\ngave_3to1 = df_treat[df_treat['ratio'] == 3]['gave'].dropna()\n\n# 1:1 vs 2:1\ntstat_12, pval_12 = stats.ttest_ind(gave_1to1, gave_2to1, equal_var=True)\n\n# 1:1 vs 3:1\ntstat_13, pval_13 = stats.ttest_ind(gave_1to1, gave_3to1, equal_var=True)\n\n# 2:1 vs 3:1\ntstat_23, pval_23 = stats.ttest_ind(gave_2to1, gave_3to1, equal_var=True)\n\n{\n    \"1:1 vs 2:1\": (tstat_12, pval_12),\n    \"1:1 vs 3:1\": (tstat_13, pval_13),\n    \"2:1 vs 3:1\": (tstat_23, pval_23)\n}\n\n{'1:1 vs 2:1': (-0.96504713432247, 0.33453168549723933),\n '1:1 vs 3:1': (-1.0150255853798622, 0.3101046637086672),\n '2:1 vs 3:1': (-0.05011583793874515, 0.9600305283739325)}\n\n\nAll three t-tests produce p-values well above 0.05, suggesting that the differences in donation rates between match ratios are not statistically significant. That is, offering a $2:$1 or $3:$1 match did not lead to higher likelihood of giving compared to a $1:$1 match.\nThis result replicates the comment the authors make on page 8, where the authors note that “gift distributions across the various matching ratios are not significantly different from one another.” The behavioral implication is striking: people seem to respond to the existence of a match, but not to how generous it is. This challenges the conventional wisdom in fundraising, which assumes that more generous matching offers will spur higher response rates.\nFrom a policy or fundraising perspective, this suggests that a simple 1:1 match may be just as effective as a more expensive 3:1 match, at least in motivating participation.\nWe now manually create dummy variables for each match ratio level and run a linear regression to test whether more generous match ratios affect the likelihood of donating.\n\n# Filter treatment group only\ndf_treat = df[df['treatment'] == 1].copy()\n\n# Convert match ratio to dummy variables\ndf_treat['ratio1'] = (df_treat['ratio'] == 1).astype(int)\ndf_treat['ratio2'] = (df_treat['ratio'] == 2).astype(int)\ndf_treat['ratio3'] = (df_treat['ratio'] == 3).astype(int)\n\n# Omit ratio1 to serve as baseline\nimport statsmodels.formula.api as smf\n\nmodel_dummy = smf.ols('gave ~ ratio2 + ratio3', data=df_treat).fit()\nmodel_dummy.summary2().tables[1]\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\n\n\nIntercept\n0.020749\n0.001391\n14.912217\n3.981333e-50\n0.018022\n0.023476\n\n\nratio2\n0.001884\n0.001968\n0.957582\n3.382805e-01\n-0.001973\n0.005741\n\n\nratio3\n0.001984\n0.001968\n1.008301\n3.133172e-01\n-0.001873\n0.005842\n\n\n\n\n\n\n\nThe regression uses $1:$1 as the reference group. The intercept (0.0207) represents the estimated donation rate under a $1:$1 match — about 2.07% of people in this group made a donation.\nThe coefficients on ratio2 and ratio3 show the change in donation rate when the match ratio is increased to $2:$1 and $3:$1, respectively:\n\nThe $2:$1 match increases the donation rate by only 0.19 percentage points.\nThe $3:$1 match increases it by a similar amount (0.20 percentage points)\n\nHowever, these coefficients are not statistically significant:\n\nThe p-values for both are above 0.3\nTheir 95% confidence intervals include zero\n\nThis means we cannot rule out the possibility that these differences happened by chance. In short, increasing the generosity of the match ratio did not significantly increase the likelihood of donating.\nThese findings are entirely consistent with the paper’s conclusion on page 8: “the gift distributions across the various matching ratios are not significantly different from one another.” This challenges the common assumption in fundraising that more generous matches (e.g., $3:$1) are always better than simpler ones like $1:$1. It appears that the presence of a match is what matters — not necessarily how large it is.\nWe now directly compute the difference in donation rates across match ratios — both from the raw data and from the fitted regression coefficients.\n\n# Raw response rates\nrate_1to1 = df_treat[df_treat['ratio'] == 1]['gave'].mean()\nrate_2to1 = df_treat[df_treat['ratio'] == 2]['gave'].mean()\nrate_3to1 = df_treat[df_treat['ratio'] == 3]['gave'].mean()\n\n# Differences from data\ndiff_21_data = rate_2to1 - rate_1to1\ndiff_32_data = rate_3to1 - rate_2to1\n\n# Differences from regression coefficients\ncoef_21 = model_dummy.params['ratio2']\ncoef_31 = model_dummy.params['ratio3']\ndiff_21_reg = coef_21\ndiff_32_reg = coef_31 - coef_21\n\n{\n    \"From data: 2:1 - 1:1\": diff_21_data,\n    \"From data: 3:1 - 2:1\": diff_32_data,\n    \"From regression: 2:1 - 1:1\": diff_21_reg,\n    \"From regression: 3:1 - 2:1\": diff_32_reg\n}\n\n{'From data: 2:1 - 1:1': 0.0018842510217149944,\n 'From data: 3:1 - 2:1': 0.00010002398025293902,\n 'From regression: 2:1 - 1:1': 0.0018842510217150174,\n 'From regression: 3:1 - 2:1': 0.00010002398025293815}\n\n\nThe results from both the raw data and regression model tell a consistent story:\n\nThe difference in donation rate between $1:$1 and $2:$1 is very small — less than 0.2 percentage points\nThe difference between $2:$1 and $3:$1 is even smaller, and in some versions may even be slightly negative\n\nFrom the regression, we see that the estimated increase from $1:$1 to $2:$1 is about 0.19 percentage points, while the additional increase from $2:$1 to $3:$1 is effectively zero.\nThese differences are also statistically insignificant, with large p-values and confidence intervals that include zero.\nWe can conclude that increasing the generosity of the match ratio — from $1:$1 to $2:$1 or $3:$1 — does not meaningfully change donation behavior. What seems to matter is simply the presence of a match, not how large it is.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of being offered a matching donation on the size of the donation. Specifically, I compare average donation amounts between treatment and control groups.\nWe begin with a t-test and then verify the result using a simple linear regression.\n\n# Drop missing values\namount_treat = df[df['treatment'] == 1]['amount'].dropna()\namount_control = df[df['control'] == 1]['amount'].dropna()\n\n# T-test\ntstat_amt, pval_amt = stats.ttest_ind(amount_treat, amount_control, equal_var=True)\ntstat_amt, pval_amt\n\n(1.8605020225753781, 0.06282038947470686)\n\n\n\nmodel_amount = smf.ols(\"amount ~ treatment\", data=df).fit()\nmodel_amount.summary2().tables[1]\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\n\n\nIntercept\n0.813268\n0.067418\n12.062995\n1.843438e-33\n0.681127\n0.945409\n\n\ntreatment\n0.153605\n0.082561\n1.860503\n6.282029e-02\n-0.008216\n0.315426\n\n\n\n\n\n\n\nThe intercept (≈ $0.81) represents the average amount given in the control group. The coefficient on treatment (≈ $0.15) shows that, on average, those in the treatment group gave 15 cents more.\nHowever, this difference is only marginally significant because the p-value from the regression is ≈ 0.063 which is just above the conventional 5% threshold and the 95% confidence interval includes zero (−0.008 to +0.315).\nThe same conclusion emerges from the t-test.\nThis suggests that being offered a matching donation may increase the total donation amount, but the evidence is not very strong. It supports the idea that treatment has a directional positive effect, but we cannot rule out chance as an explanation.\nMoreover, this is the unconditional amount — it includes many people who gave $0. In other words, the increase might be driven by more people giving, rather than each person giving significantly more. This points us toward analyzing the conditional giving effect (among those who donated), which we’ll explore next.\nWe now restrict the analysis to only those who made a donation (i.e., gave == 1). This allows us to assess how treatment affects the amount given, conditional on a donation being made.\n\n# Filter only those who gave\ndf_donated = df[df['gave'] == 1].copy()\n\n# Run OLS regression: amount ~ treatment\nimport statsmodels.formula.api as smf\nmodel_cond = smf.ols(\"amount ~ treatment\", data=df_donated).fit()\nmodel_cond.summary2().tables[1]\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\n\n\nIntercept\n45.540268\n2.423378\n18.792063\n5.473578e-68\n40.784958\n50.295579\n\n\ntreatment\n-1.668393\n2.872384\n-0.580839\n5.614756e-01\n-7.304773\n3.967986\n\n\n\n\n\n\n\nThis regression analyzes how much individuals donated, conditional on making a donation. We restrict the sample to gave == 1, and regress donation amount (amount) on treatment status.\n\nThe intercept (≈ $45.54) is the average donation amount among control group donors. This aligns exactly with Table 2A Panel A.\nThe treatment coefficient is −$1.67, with a p-value of 0.56 — it is small and statistically insignificant.\n\nThis suggests that, among people who chose to donate receiving a matching letter did not significantly change how much they gave. In fact, the (insignificant) point estimate is slightly negative, perhaps because treatment attracted more “marginal” donors (who might give smaller amounts).\nThis is not a fully causal estimate of how treatment affects donation size, because we’re conditioning on a post-treatment variable (gave == 1), which may introduce selection bias.\nThe treatment may cause more marginal givers to donate (who tend to give less) and this could bias the treatment effect downward in this conditional sample.\nTherefore, this estimate does not cleanly identify a causal effect of treatment on giving amount. The unconditional effect is the more policy-relevant and causally interpretable one.\nTo better understand the distribution of donation amounts, I plot histograms of donation sizes only among those who gave, separated by treatment status. Each plot includes a red dashed line to indicate the average donation in that group.\n\nimport matplotlib.pyplot as plt\n\n# Filter to only people who gave\ndf_donated = df[df['gave'] == 1].copy()\ndf_treat = df_donated[df_donated['treatment'] == 1]\ndf_control = df_donated[df_donated['control'] == 1]\n\n# Calculate group means\nmean_treat = df_treat['amount'].mean()\nmean_control = df_control['amount'].mean()\n\n# Plot setup\nfig, axs = plt.subplots(2, 1, figsize=(6, 7), sharey=True)\n\n# Treatment group histogram\naxs[0].hist(df_treat['amount'], bins=30, color='#1f77b4', edgecolor='white')\naxs[0].axvline(mean_treat, color='red', linestyle='--', linewidth=2)\naxs[0].set_title('Treatment Group')\naxs[0].set_xlabel('Donation Amount')\naxs[0].set_ylabel('Number of Donors')\naxs[0].text(mean_treat + 1, axs[0].get_ylim()[1]*0.9, f'Mean = {mean_treat:.2f}', color='red')\n\n# Control group histogram\naxs[1].hist(df_control['amount'], bins=30, color='#ff7f0e', edgecolor='white')\naxs[1].axvline(mean_control, color='red', linestyle='--', linewidth=2)\naxs[1].set_title('Control Group')\naxs[1].set_xlabel('Donation Amount')\naxs[1].text(mean_control + 1, axs[1].get_ylim()[1]*0.9, f'Mean = {mean_control:.2f}', color='red')\n\nplt.suptitle(\"Donation Amounts Among Donors\")\nplt.tight_layout()\nplt.show()\n\n\n\n\nHistogram of Donation Amounts by Treatment Group (among donors)\n\n\n\n\nThese histograms show the distribution of donation amounts among those who donated, separated by treatment status.\nThe red dashed line in each plot represents the average donation in that group. The control group has a mean of about $45.54, and the treatment group has a slightly lower mean (≈ $43.87), matching the regression results from earlier.\nBoth distributions are right-skewed, which means a few large donations pull the average up. Most people gave less than $50, and the treatment group appears to have more small donations, which may explain the slightly lower average.\nThis visualization confirms the finding that while the likelihood of giving increases with treatment, the amount given (conditional on giving) does not."
  },
  {
    "objectID": "blog/project1/index.html#simulation-experiment",
    "href": "blog/project1/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nWe then calculate the cumulative average of the difference in simulated outcomes across 10,000 draws and plot how this converges to the true difference of 0.004.\n\nimport numpy as np\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Simulate donation outcomes\ncontrol_draws = np.random.binomial(n=1, p=0.018, size=100000)\ntreat_draws = np.random.binomial(n=1, p=0.022, size=10000)\n\n# Match lengths (take first 10,000 of control to align)\ncontrol_sample = control_draws[:10000]\n\n# Compute difference at each observation\ndiffs = treat_draws - control_sample\n\n# Cumulative average of difference\ncum_avg = np.cumsum(diffs) / np.arange(1, len(diffs) + 1)\n\nplt.figure(figsize=(8, 5))\nplt.plot(cum_avg, label='Cumulative average difference')\nplt.axhline(0.004, color='red', linestyle='--', label='True difference (0.004)')\nplt.xlabel(\"Number of observations\")\nplt.ylabel(\"Cumulative average of difference\")\nplt.title(\"Demonstration of Law of Large Numbers\")\nplt.legend()\nplt.grid(True, linestyle='--', alpha=0.6)\nplt.tight_layout()\nplt.show()\n\n\n\n\nCumulative Average of Difference in Simulated Donation Outcomes\n\n\n\n\nThe plot shows how the cumulative average difference in donation rates between simulated treatment and control groups evolves as the sample size increases.\nAt the beginning (small n), the average is highly volatile — due to sampling noise. As more observations are added, the average stabilizes and converges to the true difference (0.004). The red dashed line represents the true gap in donation rates between the two groups.\nThis is a visual demonstration of the Law of Large Numbers: with enough independent observations, the sample average converges to the population mean.\n\n\nCentral Limit Theorem\nTo demonstrate the Central Limit Theorem (CLT), we simulate 1000 differences in donation rates between treatment and control groups, for different sample sizes (50, 200, 500, 1000). For each iteration, we draw n samples from each group and compute the average difference.\nThis allows us to observe how the sampling distribution of the difference-in-means becomes more concentrated and bell-shaped as sample size increases.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set seed\nnp.random.seed(42)\n\n# Parameters\np_control = 0.018\np_treatment = 0.022\niterations = 1000\nsample_sizes = [50, 200, 500, 1000]\n\n# Prepare plot\nfig, axs = plt.subplots(2, 2, figsize=(8, 6))\naxs = axs.flatten()\n\n# Loop over sample sizes\nfor i, n in enumerate(sample_sizes):\n    diffs = []\n    for _ in range(iterations):\n        c = np.random.binomial(1, p_control, size=n)\n        t = np.random.binomial(1, p_treatment, size=n)\n        diffs.append(t.mean() - c.mean())\n    axs[i].hist(diffs, bins=30, color='#1f77b4', edgecolor='white')\n    axs[i].axvline(0, color='black', linestyle='--', label='Zero')\n    axs[i].axvline(0.004, color='red', linestyle='--', label='True Diff')\n    axs[i].set_title(f\"Sample Size = {n}\")\n    axs[i].set_xlabel(\"Difference in Means\")\n    axs[i].set_ylabel(\"Frequency\")\n\nplt.suptitle(\"Demonstrating Central Limit Theorem: Sampling Distributions\", fontsize=14)\nplt.tight_layout()\nplt.show()\n\n\n\n\nSampling Distributions of Mean Differences at Varying Sample Sizes\n\n\n\n\nThese four histograms show the sampling distribution of the difference in mean donation rates between treatment and control, simulated 1000 times at various sample sizes.\n\nAt n = 50, the distribution is jagged, wide, and often centered around zero. This means that with small samples, there’s a lot of noise, and treatment effects may not be detectable.\nAt n = 200, the distribution becomes more bell-shaped. The peak is slightly to the right of 0 — near the true mean difference (0.004) — but zero is still near the center, implying inconclusive results are still likely.\nAt n = 500, the distribution is much tighter. Zero is closer to the tail, and the bulk of the mass is near 0.004, which means that we’re starting to reliably detect the treatment effect.\nAt n = 1000, the distribution is tightly centered near 0.004 and zero is clearly in the tail. With this sample size, we would almost always reject the null of no effect.\n\nThis simulation is a clear illustration of the Central Limit Theorem: As sample size increases, the distribution of the sample mean difference becomes more normal, less variable and converges to the true treatment effect (0.004).\nIt also explains why large sample sizes matter in A/B testing and field experiments — we need them to reliably detect small effects and to be confident in our conclusions."
  }
]